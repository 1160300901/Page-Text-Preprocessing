# 实验一 网页文本的预处理

## 一、实验目的
本次实验目的是对信息检索中网页文本预处理的流程和涉及的技术有一个全面的了解，包括抓去网页、网页正文提取、分词处理、停用词处理等环节。本次实验所要用到的知识如下：
- 基本编程能力（文件处理、网页爬取等）
- 分词、停用词处理

## 二、实验内容

1. 网页的抓取和正文提取
爬取至少 1000 个网页，其中包含附件的网页不少于 100 个，然后提取网页标题和网页正文，以及网页中的附件并保存附件到本地，然后将附件名称记录在 file_name 字段中。网页正文和网页标题可以自行定义，但一般应该是网页中你最关注的内容。例如在一般的新闻网页上，就以新闻标题为网页标题，新闻内容为网页正文，而其他诸如导航栏、广告等都是不关心的内容。为保证可读性，网页正文中不应该包含太多 HTML 标签（如<p>、<img>等）。将爬取下来的数据保存为 json 格式，具体格式如下： 
{
"url": "http://today.hit.edu.cn/article/2019/04/23/66256", 
"title": "英国牛津大学暑期项目招生通知", 
"parapraghs": "我校2019年学生赴“英国牛津大学暑期项目”申请工作......”,
"file_name": ["项目介绍.docx", "LMH Summer Programmes Application.doc"]
}

2. 分词处理、去停用词处理
将提取的网页文本进行分词和去停用词处理，并将结果保存。分词工具使用pyltp。停用词表采用由社会计算与信息检索研究中心发布的停用词表 (stop_words.txt)。最后将经过分词和去停用词后的结果保存，格式如下：
{
"url": "http://today.hit.edu.cn/article/2019/04/23/66256",
"segmented_title": ["英国", "牛津", "大学", "暑期", "项目", "招生", "通知"],
"segmented_parapraghs": ["我校", "2019年", "学生", "赴", "英国", "牛津", "大学", "暑期", "项目", "申请", "工作", "已", "启动",......,
	"file_name": ["项目介绍.docx", "LMH Summer Programmes Application.doc"]
}


## 三、实验过程及结果
### 3.1 网页的抓取和正文提取
（1）网页抓取
在本次实验中我尝试抓取了网易新闻、新浪新闻、搜狗新闻主页，由于缺少文本附件，最后选取了今日哈工大的网页，下面以今日哈工大为例，根据具体的网页说明爬取的过程。
分析网站的结构可以知道，普通新闻里很少有附件，一般都是公告公示里带有附件，所以从公告公示栏开始